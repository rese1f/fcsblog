<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>LLM Defeated in Open-ended Problems | Frontier-CS Blog Posts</title> <meta name="author" content="Frontier-CS Blog"> <meta name="description" content="Modern LLMs claim superhuman algorithmic abilities, but what happens when there is no strict verifier? We analyze how multi-turn 'optimization' in Frontier-CS exposes the cognitive ceiling and catastrophic failures of AI in open-ended problem solving."> <meta name="keywords" content="machine-learning, ml, deep-learning, frontier-cs, blog"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="icon" type="image/svg+xml" href="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2032%2032'%3E%3Crect%20width='32'%20height='32'%20fill='%23003262'%20rx='4'/%3E%3Ctext%20x='16'%20y='22'%20font-family='Georgia,%20serif'%20font-size='20'%20font-weight='bold'%20fill='white'%20text-anchor='middle'%3EB%3C/text%3E%3C/svg%3E"> <link rel="shortcut icon" href="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2032%2032'%3E%3Crect%20width='32'%20height='32'%20fill='%23003262'%20rx='4'/%3E%3Ctext%20x='16'%20y='22'%20font-family='Georgia,%20serif'%20font-size='20'%20font-weight='bold'%20fill='white'%20text-anchor='middle'%3EB%3C/text%3E%3C/svg%3E"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://frontier-cs.org/blog/negative-optimization/"> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> <style type="text/css">d-article img{max-width:100%;height:auto;display:block;margin:1.5rem auto;border-radius:6px}d-article p img{display:block;margin-left:auto;margin-right:auto}</style> </head> <body> <d-front-matter> <script async type="text/json">{
      "title": "LLM Defeated in Open-ended Problems",
      "description": "Modern LLMs claim superhuman algorithmic abilities, but what happens when there is no strict verifier? We analyze how multi-turn 'optimization' in Frontier-CS exposes the cognitive ceiling and catastrophic failures of AI in open-ended problem solving.",
      "published": "2026-02-26T12:00:00Z",
      "authors": [
        {
          "author": "Wenyuan Huang",
          "authorURL": "https://whuang369.com/",
          "affiliations": [
            {
              "name": "University of Wisconsin Madison",
              "url": ""
            }
          ]
        },
        {
          "author": "Shang Zhou",
          "authorURL": "https://scholar.google.com/citations?user=_0dEBNAAAAAJ",
          "affiliations": [
            {
              "name": "University of California, San Diego",
              "url": ""
            }
          ]
        },
        {
          "author": "Frontier-CS team",
          "authorURL": "https://frontier-cs.org",
          "affiliations": [
            {
              "name": "",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Frontier-CS blog posts </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> </ul> </div> </div> </nav> </header> <div class="post distill"> <d-title> <h1>LLM Defeated in Open-ended Problems</h1> <p>Modern LLMs claim superhuman algorithmic abilities, but what happens when there is no strict verifier? We analyze how multi-turn 'optimization' in Frontier-CS exposes the cognitive ceiling and catastrophic failures of AI in open-ended problem solving.</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div><a href="#the-real-world-evaluation-gap">The Real-World Evaluation Gap</a></div> <div><a href="#case-study-the-hedgehog-graph">Case Study - The Hedgehog Graph</a></div> <div><a href="#the-anatomy-of-the-trap">The Anatomy of the Trap</a></div> <div><a href="#the-post-training-flaw">The Post-Training Flaw</a></div> <div><a href="#real-world-implications">Real-World Implications</a></div> </nav> </d-contents> <p><img src="/assets/img/2026-02-14-negative-optimization/image2.png" alt="Performance Contrast: Algorithm vs. Heuristic" class="hero"></p> <p>According to official technical reports, Deep Think’s model achieves a Codeforces elo rating of 3455. Our independent evaluation estimates Deep Think’s actual rating to be roughly 3299. However, during the open-ended AtCoder Heuristic Contest (AHC), the model only managed non-zero scores on under <strong>50%</strong> of the problems — a strong contrast to its performance on traditional algorithms. We conducted detailed cause analysis and case study based on the result.</p> <h2 id="the-real-world-evaluation-gap">The Real-World Evaluation Gap</h2> <p>In actual working environment, a consistent trend has been noticed widely: Modern LLMs’ (etc. Deep Think) effectiveness in actual work environments isn’t nearly as outstanding as their amazing performance on traditional algorithmic benchmarks shows.</p> <p>Unlike solving standard competitive programming problems with fixed boundaries, real-world work fundamentally tests a model’s capacity for continual learning and adaptation. There is a significant mismatch between current model behaviors and what traditional algorithmic benchmarks actually measure. To truly evaluate a model’s ability to handle complex, ambiguous scenarios, we must test it using open-ended problems.</p> <p>To illustrate this, we evaluated Deep Think on two entirely different tracks: 30 of the newest Codeforces problems with a high difficulty rating of 2500+ (representing traditional, strict-boundary algorithmic tasks), alongside all 33 short-format problems from the AtCoder Heuristic Contest (representing open-ended, heuristic challenges).</p> <p><img src="/assets/img/2026-02-14-negative-optimization/image1.png" alt="Performance Contrast: Algorithm vs. Heuristic" class="hero"></p> <p>The data reveals a suprising contrast. We found that the model produces a massive volume of failure cases when attempting open-ended heuristic problems, given it’s near human. This high failure rate completely mismatches the model’s supposedly superhuman, high-confidence performance in traditional algorithmic domains.</p> <p>To understand exactly why this breakdown occurs and how models fall into these optimization traps, we conducted a detailed case study.</p> <h2 id="case-study-the-hedgehog-graph">Case Study: The Hedgehog Graph</h2> <p>To understand this collapse, let’s look at a specific interaction involving the interactive problem <strong>Hedgehog Graph</strong> (no. 222).</p> <ul> <li> <strong>The Setup:</strong> You are given a directed graph with 1,000,000 vertices. Each vertex has exactly one outgoing edge, eventually flowing into a single directed cycle.</li> <li> <strong>The Goal:</strong> Determine the length of the cycle, S.</li> <li> <strong>The Tool:</strong> You can make queries <code class="language-plaintext highlighter-rouge">? v x</code>, returning the vertex reached by taking x steps from v.</li> <li> <strong>The Constraint:</strong> You have a budget of 2500 queries.</li> <li> <strong>The Score:</strong> Using 500 or fewer queries yields 100 points. The score decays quadratically up to 2500 queries, after which the score drops to 0.</li> </ul> <h3 id="round-1-the-robust-solution">Round 1: The Robust Solution</h3> <p>In its first attempt, the model defaulted to a highly stable, probabilistic approach based on the <strong>Birthday Paradox</strong>. It queried random step sizes, stored the resulting vertices, and looked for collisions.</p> \[E[\text{queries}] \approx \sqrt{\frac{\pi}{2} S}\] <p>For a cycle of 1,000,000 vertices, the expected number of queries is roughly 1200. This is a mathematically robust baseline. It doesn’t matter if S is prime or composite; the logic holds. The model correctly noted this would yield a partial score of around 20 points, well within the 2500 absolute limit.</p> <h3 id="round-2-incorrect-optimization">Round 2: Incorrect Optimization</h3> <p>A human competitor at this stage would secure the 20 points and attempt to safely optimize the constant factors or memory usage. The LLM, prompted to improve its score, took a wildly different path. It abandoned the stable baseline entirely for a “Scaled Collision” strategy.</p> <p>The model attempted to split its query budget into stages, testing highly composite numbers to exploit number theory and artificially force faster collisions.</p> <ul> <li> <strong>Stage 1:</strong> Try factors of primes up to 47 for 220 queries.</li> <li> <strong>Stage 2:</strong> Try factors of primes up to 43 for 220 queries.</li> <li> <strong>Fallback:</strong> Use the remaining budget for random collisions.</li> </ul> <h2 id="the-anatomy-of-the-trap">The Anatomy of the Trap</h2> <p><img src="/assets/img/2026-02-14-negative-optimization/image5.jpg" alt="Performance Contrast: Algorithm vs. Heuristic" class="hero"></p> <p>This looks like sophisticated engineering, but it is a catastrophic theoretical failure.</p> <p>The LLM optimized purely for the <strong>average case</strong> (composite numbers) while entirely blinding itself to the <strong>worst case</strong> (prime numbers). If the cycle length S is a large prime like 999,983, it shares no factors with the model’s composite guesses. The effective cycle length remains unchanged, and the “optimization” yields zero benefit.</p> <p>Then as a result, the model fragmented its strict query budget. By the time it realized its heuristic trick was failing on prime numbers, it had wasted 800 queries. Starting the fallback random search with a massive 800-query debt pushed the total past the 2500 limit.</p> <p><strong>The result: A stable 20-point baseline was “optimized” into a 0-point failure.</strong></p> <h2 id="the-post-training-flaw">The Post-Training Flaw</h2> <p>This behavior highlights a profound issue with modern LLMs. During post-training, AI institutions frequently optimize for state-of-the-art benchmark scores by artificially encouraging the model to take risks instead of stable choices. By generating multiple diverse rollouts and selecting only the highest-scoring one—a technique known as Best-of-N sampling—the training process disproportionately rewards high-variance, speculative logic over safe, incremental improvements. Consequently, the fully trained model naturally defaults to risky, “all-or-nothing” gambles rather than stable optimization methods.</p> <p><img src="/assets/img/2026-02-14-negative-optimization/image4.jpg" alt="Performance Contrast: Algorithm vs. Heuristic" class="hero"></p> <p>When faced with a difficult optimization task lacking a strict, immediate verifier, the model resorts to a “lazy” strategy. Instead of doing the grueling work of designing a universally stable improvement, it speculates. It chooses unstable, point-cheating tricks that create the illusion of problem-solving but performs terribly under the pressure of strong, worst-case test data. The model effectively hit a cognitive ceiling, opting for giving an incorrect optimization rather than acknowledging the limits of its reasoning.</p> <h2 id="real-world-implications">Real-World Implications</h2> <p><img src="/assets/img/2026-02-14-negative-optimization/image6.jpg" alt="Performance Contrast: Algorithm vs. Heuristic" class="hero"></p> <p>This is why continuous scoring in benchmarks like Frontier-CS is critical. In a binary pass/fail system, this regression might be masked.</p> <p>More importantly, the open-ended problems in Frontier-CS reveals the realities of actual software engineering. Production codebases and complex system architectures do not have a absolute, formal verifier. If we trust LLMs to autonomously optimize systems without strict bounds, they are highly intended to introducing fragile, edge-case-blind logic that works in theory but causes systemic collapse in practice.</p> <p>While LLMs undoubtedly possess elite capabilities for isolated, well-defined algorithms, their performance in open-ended reasoning remains fundamentally unreliable. Treating them as omnipotent architects rather than powerful, specialized tools is a trap we cannot afford to fall into.</p> </d-article> </div> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> </body> </html>